{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 6917635,
          "sourceType": "datasetVersion",
          "datasetId": 3972131
        }
      ],
      "dockerImageVersionId": 30558,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Employee Performance Analysis- Using CRISP DM Methodology"
      ],
      "metadata": {
        "id": "1OW8pxQ9maDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### INX Future Inc"
      ],
      "metadata": {
        "id": "-DPQo6hBmaDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Business Understanding\n",
        "### Problem Statement"
      ],
      "metadata": {
        "id": "nVvqHH3emaDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### INX Future Inc , (referred as INX ) , is one of the leading data analytics and automation solutions provider\n",
        "with over 15 years of global business presence. INX is consistently rated as top 20 best employers past 5 years. Recent years, the employee performance indexes are not healthy and this is becoming a growing concerns among the top management.CEO, Mr. Brain, knows the issues but concerned to take any actions in penalizing non-performing employees as this would affect the employee morale of all the employees in general and may further reduce the performance\n",
        "\n",
        "The following insights are expected from this project.\n",
        "\n",
        "1. Department wise performances\n",
        "2. Top 3 Important Factors effecting employee performance\n",
        "3. A trained model which can predict the employee performance based on factors as inputs. This will be used to hire employees\n",
        "4. Recommendations to improve the employee performance based on insights from analysis."
      ],
      "metadata": {
        "id": "LpsTPwlEmaDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Understanding\n",
        "The data for training the model was collected from the company INX Future Inc. The data\n",
        "collected included 1200 employeeâ€™s performance appraisal records, described by 28 parameters. the parameters show the different attributes of an employee based on which the prediction is to be made.\n",
        "\n",
        "### Features present in the dataset\n",
        "\n",
        "1-EmpNumber\n",
        "\n",
        "2-Age\n",
        "\n",
        "3-Gender\n",
        "\n",
        "4-EducationBackground\n",
        "\n",
        "5-MaritalStatus\n",
        "\n",
        "6-EmpDepartment\n",
        "\n",
        "7-EmpJobRole\n",
        "\n",
        "8-BusinessTravelFrequency\n",
        "\n",
        "9-DistanceFromHome\n",
        "\n",
        "10-EmpEducationLevel\n",
        "\n",
        "11-EmpEnvironmentSatisfaction\n",
        "\n",
        "12-EmpHourlyRate\n",
        "\n",
        "13-EmpJobInvolvement\n",
        "\n",
        "14-EmpJobLevel\n",
        "\n",
        "15-EmpJobSatisfaction\n",
        "\n",
        "16-NumCompaniesWorked\n",
        "\n",
        "17-OverTime\n",
        "\n",
        "18-EmpLastSalaryHikePercent\n",
        "\n",
        "19-EmpRelationshipSatisfaction\n",
        "\n",
        "20-TotalWorkExperienceInYears\n",
        "\n",
        "21-TrainingTimesLastYear\n",
        "\n",
        "22-EmpWorkLifeBalance\n",
        "\n",
        "23-ExperienceYearsAtThisCompany\n",
        "\n",
        "24-ExperienceYearsInCurrentRole\n",
        "\n",
        "25-YearsSinceLastPromotion\n",
        "\n",
        "26-YearsWithCurrManager\n",
        "\n",
        "27-Attrition\n",
        "\n",
        "28-PerformanceRating\n"
      ],
      "metadata": {
        "id": "5CD2ygtkmaDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing essential libraries"
      ],
      "metadata": {
        "id": "AehxKEv5maDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Numpy' is used for mathematical operations on large, multi-dimensional arrays and matrices\n",
        "import numpy as np\n",
        "\n",
        "# 'Pandas' is used for data manipulation and analysis\n",
        "import pandas as pd\n",
        "\n",
        "# 'Seaborn' is based on matplotlib; used for plotting statistical graphics\n",
        "import seaborn as sns\n",
        "\n",
        "# 'Matplotlib' is a data visualization library for 2D and 3D plots, built on numpy\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "# suppress display of warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "ARR67C3ImaD0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the dataset"
      ],
      "metadata": {
        "id": "7JGg9hDbmaD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the excel file\n",
        "df = pd.read_excel(\"INX_Future_Inc_Employee_Performance_CDS_Project2_Data_V1.8.xls\")"
      ],
      "metadata": {
        "id": "09WzOqTxmaD1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "wSH_aoTAmaD2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring the dataset\n",
        "### Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "NmgDxxk2maD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns number of rows and columns of the dataset\n",
        "df.shape"
      ],
      "metadata": {
        "id": "azqjziEMmaD2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns the first 5 number of rows\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "MmiofVtkmaD2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns the last 5 number of rows\n",
        "df.tail(5)"
      ],
      "metadata": {
        "id": "mX_NHzRKmaD2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns an object with all of the column headers\n",
        "df.columns"
      ],
      "metadata": {
        "id": "KtfE4n5amaD3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns basic information on all columns\n",
        "df.info()"
      ],
      "metadata": {
        "id": "-ON7DN0OmaD3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns basic statistics on numeric columns\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "dbjUoivJmaD3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns different datatypes for each columns\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "7dLYVBWMmaD3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns total number of missing values for each columns\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "jz2p57XzmaD3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Visualization"
      ],
      "metadata": {
        "id": "u9KXgkcqmaD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# New Dataframe is created to analyze department wise performance.\n",
        "dept = df.iloc[:,[5,27]].copy()\n",
        "dept_per = dept.copy()"
      ],
      "metadata": {
        "id": "2LbZrNxsmaD3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the mean performance of all the departments and plotting bar graph using seaborn.\n",
        "dept_per.groupby(by='EmpDepartment')['PerformanceRating'].mean()"
      ],
      "metadata": {
        "id": "zfj5T4tXmaD3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,4.5))\n",
        "sns.barplot(dept_per['EmpDepartment'],dept_per['PerformanceRating'])"
      ],
      "metadata": {
        "id": "UrEvooAqmaD4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze all department separately\n",
        "dept_per.groupby(by='EmpDepartment')['PerformanceRating'].value_counts()"
      ],
      "metadata": {
        "id": "oeuNS-lRmaD4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating new Dataframe to analyze each department separately\n",
        "department = pd.get_dummies(dept_per['EmpDepartment'])\n",
        "performance = pd.DataFrame(dept_per['PerformanceRating'])\n",
        "dept_rating = pd.concat([department,performance],axis=1)"
      ],
      "metadata": {
        "id": "uIjqJocFmaD4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting separate bar graph for performance of each department using seaborn\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.subplot(2,3,1)\n",
        "sns.barplot(dept_rating['PerformanceRating'],dept_rating['Sales'])\n",
        "plt.subplot(2,3,2)\n",
        "sns.barplot(dept_rating['PerformanceRating'],dept_rating['Development'])\n",
        "plt.subplot(2,3,3)\n",
        "sns.barplot(dept_rating['PerformanceRating'],dept_rating['Research & Development'])\n",
        "plt.subplot(2,3,4)\n",
        "sns.barplot(dept_rating['PerformanceRating'],dept_rating['Human Resources'])\n",
        "plt.subplot(2,3,5)\n",
        "sns.barplot(dept_rating['PerformanceRating'],dept_rating['Finance'])\n",
        "plt.subplot(2,3,6)\n",
        "sns.barplot(dept_rating['PerformanceRating'],dept_rating['Data Science'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tJ3210PrmaD4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning\n",
        "The raw data we have is completely clean. We checked for missing values but data contained no missing\n",
        "values. To get proper prediction we need to do label encoding for categorical values"
      ],
      "metadata": {
        "id": "UUntG_UImaD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlation Plot"
      ],
      "metadata": {
        "id": "sHdxU3JamaD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,18))\n",
        "sns.heatmap(df.corr(), cmap='YlGnBu',annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nRpSXi9amaD4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df, diag_kind='kde')"
      ],
      "metadata": {
        "id": "t5g7hdKbmaD4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Encoding/Data wrangling"
      ],
      "metadata": {
        "id": "vL0kBBDMmaD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding all the ordinal columns and creating a dummy variable for them to see if there are any effects on Performance Rating\n",
        "enc = LabelEncoder()\n",
        "for i in (2,3,4,5,6,7,16,26):\n",
        "    df.iloc[:,i] = enc.fit_transform(df.iloc[:,i])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "CEGiMDITmaD5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Selection"
      ],
      "metadata": {
        "id": "iMtIaw6ImaD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding out the correlation coeffecient to find out which predictors are significant.\n",
        "df.corr()"
      ],
      "metadata": {
        "id": "dBkx4zzFmaD5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a lot of columns in the predictor variable. So, the correlation coeffecient is calculated to see which of them are important and these are then used for training methods. From there, we also get the top factors which affect performance. We can see that the most important features selectd were Department, Job Role, Environment Satisfaction, Last Salary Hike Percent, Work Life Balance, Experience Years At This Company, Experience Years In Current Role, Years Since Last Promotion, Years With Current Manager. These were selected because their correlation coeffecient with Performance Rating was more than 0.1. Standardization and Label Encoding was also used for feature transformation.\n",
        "\n",
        "A separate analysis considering all the predictors was carried out but it resulted in decreasing the accuracy. Similarly, Principal Component Analysis also reduces the accuracy.\n",
        "Top 3 factors which affect the employee performance are-\n",
        "1. Employee EnvironmentSatisfaction\n",
        "2. Employee Last Salary Hike Percent\n",
        "3. Years Since Last Promotion"
      ],
      "metadata": {
        "id": "UNL7-EUOmaD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the first columns as it is of no use for analysis.\n",
        "df.drop(['EmpNumber'],inplace=True,axis=1)"
      ],
      "metadata": {
        "id": "mgMXf4ALmaD5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Selected only the important columns\n",
        "y = df.PerformanceRating\n",
        "X = df.iloc[:,[4,5,9,16,20,21,22,23,24]] # Taking only variables with correlation coeffecient greater than 0.1\n",
        "X.head()"
      ],
      "metadata": {
        "id": "jdJFNXl1maD5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-Test Split"
      ],
      "metadata": {
        "id": "KSVRIqwmmaD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=10)\n",
        "X_train.shape, X_test.shape,y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "uHLgH0yKmaD5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Scaling"
      ],
      "metadata": {
        "id": "Pi8aOWWimaED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardization technique is used\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "H2h0AB9EmaED"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "IfooflUVmaED"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling\n",
        "Used algorithms are Logistic Regression, Support Vector Machine, Decision Tree, Random Forest,Naive Bayes Bernoulli,K-Nearest Neighbor and Artificial Neural Network"
      ],
      "metadata": {
        "id": "6yCbSoKhmaED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Logistic Regression"
      ],
      "metadata": {
        "id": "KmFBM0yqmaEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model_lr = LogisticRegression()\n",
        "model_lr.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "cDHVK8ESmaEE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the model\n",
        "y_predict_lr = model_lr.predict(X_test)"
      ],
      "metadata": {
        "id": "JTfM6f15maEE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding accuracy, precision, recall and confusion matrix\n",
        "print(accuracy_score(y_test,y_predict_lr))\n",
        "print(classification_report(y_test,y_predict_lr))"
      ],
      "metadata": {
        "id": "pFK3xSqqmaEE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test,y_predict_lr)"
      ],
      "metadata": {
        "id": "2inbxChSmaEE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lr= accuracy_score(y_test,y_predict_lr)"
      ],
      "metadata": {
        "id": "1bx48WnRmaEE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Support Vector Machine"
      ],
      "metadata": {
        "id": "0v8V3HZZmaEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "from sklearn.svm import SVC\n",
        "rbf_svc = SVC(kernel='rbf', C=100, random_state=10).fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "G5vXumBamaEF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the model\n",
        "y_predict_svm = rbf_svc.predict(X_test)"
      ],
      "metadata": {
        "id": "CN_IqNInmaEF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding accuracy, precision, recall and confusion matrix\n",
        "print(accuracy_score(y_test,y_predict_svm))\n",
        "print(classification_report(y_test,y_predict_svm))"
      ],
      "metadata": {
        "id": "zu4UAf3gmaEF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test,y_predict_svm)"
      ],
      "metadata": {
        "id": "kNNCjhw5maEF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "svm= accuracy_score(y_test,y_predict_svm)"
      ],
      "metadata": {
        "id": "Vt97ewS4maEF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Decision Tree with GridSearchCV"
      ],
      "metadata": {
        "id": "vyw7Sp-kmaEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "classifier_dt=DecisionTreeClassifier(random_state=42,splitter='best')\n",
        "parameters=[{'min_samples_split':[2,3,4,5],'criterion':['gini']},{'min_samples_split':[2,3,4,5],'criterion':['entropy']}]\n",
        "\n",
        "model_dt_grid=GridSearchCV(estimator=classifier_dt, param_grid=parameters, scoring='accuracy',cv=10)\n",
        "model_dt_grid.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "x6cNoM-YmaEF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_dt_grid.best_params_"
      ],
      "metadata": {
        "id": "ONiNiCDwmaEG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the model\n",
        "y_predict_dt = model_dt_grid.predict(X_test)"
      ],
      "metadata": {
        "id": "sROKrJjFmaEG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding accuracy, precision, recall and confusion matrix\n",
        "print(accuracy_score(y_test,y_predict_dt))\n",
        "print(classification_report(y_test,y_predict_dt))"
      ],
      "metadata": {
        "id": "b0UDCZEQmaEG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test,y_predict_dt)"
      ],
      "metadata": {
        "id": "r9SmafNsmaEG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dt_grid= accuracy_score(y_test,y_predict_dt)"
      ],
      "metadata": {
        "id": "G31S-yg7maEG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Random Forest with GridSearchCV"
      ],
      "metadata": {
        "id": "U1bfjJkKmaEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "classifier_rfg=RandomForestClassifier(random_state=33,n_estimators=23)\n",
        "parameters=[{'min_samples_split':[2,3,4,5],'criterion':['gini','entropy'],'min_samples_leaf':[1,2,3]}]\n",
        "\n",
        "model_rf_grid=GridSearchCV(estimator=classifier_rfg, param_grid=parameters, scoring='accuracy',cv=10)\n",
        "model_rf_grid.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "bZpoiAurmaEG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_rf_grid.best_params_"
      ],
      "metadata": {
        "id": "GclQxsTwmaEG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the model\n",
        "y_predict_rf = model_rf_grid.predict(X_test)"
      ],
      "metadata": {
        "id": "2THmVcn6maEH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding accuracy, precision, recall and confusion matrix\n",
        "print(accuracy_score(y_test,y_predict_rf))\n",
        "print(classification_report(y_test,y_predict_rf))"
      ],
      "metadata": {
        "id": "M9a93em3maEH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test,y_predict_rf)"
      ],
      "metadata": {
        "id": "iW0FpIZbmaEH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "rf_grid= accuracy_score(y_test,y_predict_rf)"
      ],
      "metadata": {
        "id": "xEdsiiZqmaEH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Naive Bayes Bernoulli"
      ],
      "metadata": {
        "id": "cD-WeeLBmaEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "model_nb = BernoulliNB()\n",
        "model_nb.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "SKEiP-ogmaEH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the model\n",
        "y_predict_nb = model_nb.predict(X_test)"
      ],
      "metadata": {
        "id": "GipAhAinmaEH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding accuracy, precision, recall and confusion matrix\n",
        "print(accuracy_score(y_test,y_predict_nb))\n",
        "print(classification_report(y_test,y_predict_nb))"
      ],
      "metadata": {
        "id": "aBg-7x6AmaEH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test,y_predict_nb)"
      ],
      "metadata": {
        "id": "5MPUdkJ8maEH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "nb= accuracy_score(y_test,y_predict_nb)"
      ],
      "metadata": {
        "id": "kwjxTdbZmaEH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. K-Nearest Neighbor"
      ],
      "metadata": {
        "id": "VKRiiyK_maEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model_knn = KNeighborsClassifier(n_neighbors=10,metric='euclidean') # Maximum accuracy for n=10\n",
        "model_knn.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "-NR85bG1maEI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the model\n",
        "y_predict_knn = model_knn.predict(X_test)"
      ],
      "metadata": {
        "id": "C1M3KgFImaEI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding accuracy, precision, recall and confusion matrix\n",
        "print(accuracy_score(y_test,y_predict_knn))\n",
        "print(classification_report(y_test,y_predict_knn))"
      ],
      "metadata": {
        "id": "CkeLGgVlmaEI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test,y_predict_knn)"
      ],
      "metadata": {
        "id": "tV3PoE8omaEI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "knn= accuracy_score(y_test,y_predict_knn)"
      ],
      "metadata": {
        "id": "oERddbsqmaEI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Artificial Neural Network"
      ],
      "metadata": {
        "id": "892O9lSdmaEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "model_mlp = MLPClassifier(hidden_layer_sizes=(100,100,100),batch_size=10,learning_rate_init=0.01,max_iter=2000,random_state=10)\n",
        "model_mlp.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "E26eBIQ4maEI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the model\n",
        "y_predict_mlp = model_mlp.predict(X_test)"
      ],
      "metadata": {
        "id": "rMLajYOimaEI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding accuracy, precision, recall and confusion matrix\n",
        "print(accuracy_score(y_test,y_predict_mlp))\n",
        "print(classification_report(y_test,y_predict_mlp))"
      ],
      "metadata": {
        "id": "xnjzPfGMmaEI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test,y_predict_mlp)"
      ],
      "metadata": {
        "id": "OnbILMLUmaEI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ANN= accuracy_score(y_test,y_predict_mlp)"
      ],
      "metadata": {
        "id": "RWr32RClmaEI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Performance\n",
        "Accuracy score comparison chart"
      ],
      "metadata": {
        "id": "3hPDca8EmaEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Accuracy_Score = [lr,svm,dt_grid,rf_grid,nb,knn,ANN]\n",
        "Models = ['Logistic Regression', 'Support Vector Machine' , 'Decision Tree with GridSearchCV', 'Random Forest with GridSearchCV',\n",
        "          'Naive Bayes Bernoulli', 'K-Nearest Neighbor', 'Artificial Neural Network']"
      ],
      "metadata": {
        "id": "ShAP-HZEmaEJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(Accuracy_Score, Models, color=\"xkcd:baby poop green\")\n",
        "plt.xlabel('Accuracy Score')\n",
        "plt.title('Accuracy Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_bTK0S0-maEJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis\n",
        "The data is supervised and categorical. The predictor variables are ordinal and a few among them are nominal. The target variable 'Performance Rating' is ordinal.\n",
        "\n",
        "To analyze the data, various data processing techniques like Label Encoding and Standardization is used.\n",
        "\n",
        "Correlation Coeffecient is used to interpret the relationship between variables.\n",
        "\n",
        "The most important features selected are Department, Job Role, Environment Satisfaction, Last Salary Hike Percent, Work Life Balance, Experience Years At This Company, Experience Years In Current Role, Years Since Last Promotion, Years With Current Manager.\n",
        "\n",
        "For training the data and predicting the target, algorithms used are Logistic Regression, Support Vector Machine, Decision Tree, Random Forest, Naive Bayes, K-Nearest Neighbor and Artificial Neural Network.\n",
        "\n",
        "A separate analysis of Department wise Performance is done as well."
      ],
      "metadata": {
        "id": "OM7qKUL4maEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results\n",
        "Random Forest with GridSearchCV gives 94% accuracy.\n",
        "\n",
        "The features that are positively correlated are Environment Satisfaction, Last Salary Hike Percent & Worklife Balance. This means that if these factors increases, Performance Rating will increase. On the other hand, the features that are negatively correlated are Years Since Last Promotion, Experience Years at this Company, Experience years in Current Role & Years with Current Manager. This means that if these factors increases, Performance Rating will go down.\n",
        "\n",
        "The top 3 features effecting employee performances are:\n",
        "Employee Environment Satisfaction\n",
        "Employee Last Salary Hike Percent\n",
        "Years since last promotion"
      ],
      "metadata": {
        "id": "OhtRohC-maEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis and Insights\n",
        "It is observed that the maximum accuracy is obtained when we used Random Forest with GridSearchCV which is 94%. Decision tree and Artificial neural networks also yielded an accuracy of 92.5%.\n",
        "\n",
        "### Recommendation\n",
        "We can conclude that the company should provide a better environment as it increases the performance drastically. The company should increase the salary of the employee from time to time and help them maintain a worklife balance. On the other hand, shuffling the manager from time to time will also affect performance."
      ],
      "metadata": {
        "id": "mXstT6JcmaEJ"
      }
    }
  ]
}